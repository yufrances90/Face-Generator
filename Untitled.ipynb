{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip processed-celeba-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'processed-celeba-small/'\n",
    "\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import problem_unittests as tests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the CelebA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, image_size, data_dir='processed_celeba_small/'):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param batch_size: The size of each batch; the number of images in a batch\n",
    "    :param img_size: The square size of the image data (x, y)\n",
    "    :param data_dir: Directory where image data is located\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    \n",
    "    # resize and normalize the images\n",
    "    transform = transforms.Compose([transforms.Resize(image_size), \n",
    "                                    transforms.ToTensor()])\n",
    "    \n",
    "    # get training and test directories\n",
    "    image_path = f'./{data_dir}celeba'\n",
    "    \n",
    "    # define datasets using ImageFolder\n",
    "    image_dataset = datasets.ImageFolder(image_path, transform)\n",
    "    \n",
    "    return DataLoader(dataset=image_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_size = 128\n",
    "\n",
    "celeba_train_loader = get_dataloader(batch_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(celeba_train_loader)\n",
    "images, _ = dataiter.next() # _ for no labels\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "plot_size=16\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, feature_range=(-1, 1)):\n",
    "    ''' Scale takes in an image x and returns that image, scaled\n",
    "       with a feature_range of pixel values from -1 to 1. \n",
    "       This function assumes that the input x is already scaled from 0-1.'''\n",
    "    # assume x is scaled to (0, 1)\n",
    "    # scale to feature_range and return scaled x\n",
    "    \n",
    "    min, max = feature_range\n",
    "\n",
    "    return x * (max - min) + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# check scaled range\n",
    "# should be close to -1 to 1\n",
    "img = images[0]\n",
    "scaled_img = scale(img)\n",
    "\n",
    "print('Min: ', scaled_img.min())\n",
    "print('Max: ', scaled_img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_dim):\n",
    "        \"\"\"\n",
    "        Initialize the Discriminator Module\n",
    "        :param conv_dim: The depth of the first convolutional layer\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        conv_dim_0 = conv_dim\n",
    "        conv_dim_1 = conv_dim * 5\n",
    "        conv_dim_2 = conv_dim * 5 * 5\n",
    "        conv_dim_3 = conv_dim * 5 * 5 * 5\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, conv_dim_0, 5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(conv_dim_0, conv_dim_1, 5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(conv_dim_1, conv_dim_2, 5, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(conv_dim_2, conv_dim_3, 5, stride=2, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(conv_dim_1)\n",
    "        self.bn3 = nn.BatchNorm2d(conv_dim_2)\n",
    "        self.bn4 = nn.BatchNorm2d(conv_dim_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(conv_dim_3, conv_dim_3)\n",
    "        self.fc2 = nn.Linear(conv_dim_3, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: Discriminator logits; the output of the neural network\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.bn4(self.conv4(x))\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.test_discriminator(Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_size, conv_dim):\n",
    "        \"\"\"\n",
    "        Initialize the Generator Module\n",
    "        :param z_size: The length of the input latent vector, z\n",
    "        :param conv_dim: The depth of the inputs to the *last* transpose convolutional layer\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        conv_dim_0 = conv_dim\n",
    "        conv_dim_1 = conv_dim * 5\n",
    "        conv_dim_2 = conv_dim * 5 * 5\n",
    "        conv_dim_3 = conv_dim * 5 * 5 * 5\n",
    "        \n",
    "        self.fc1 = nn.Linear(z_size, conv_dim_3)\n",
    "        self.fc2 = nn.Linear(conv_dim_3, conv_dim_3)\n",
    "        \n",
    "        self.convT1 = nn.ConvTranspose2d(conv_dim_3, conv_dim_2, 5, stride=2, padding=1)\n",
    "        self.convT2 = nn.ConvTranspose2d(conv_dim_2, conv_dim_1, 5, stride=2, padding=1)\n",
    "        self.convT3 = nn.ConvTranspose2d(conv_dim_1, conv_dim_0, 5, stride=2, padding=1)\n",
    "        self.convT4 = nn.ConvTranspose2d(conv_dim_0, 3, 4, stride=2, padding=0)\n",
    "        \n",
    "        self.bnT1 = nn.BatchNorm2d(conv_dim_2)\n",
    "        self.bnT2 = nn.BatchNorm2d(conv_dim_1)\n",
    "        self.bnT3 = nn.BatchNorm2d(conv_dim_0)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: A 32x32x3 Tensor image as output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = x.view(-1, self.conv_dim * 5 * 5 * 5, 1, 1)\n",
    "        \n",
    "        x = self.bnT1(self.convT1(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.bnT2(self.convT2(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.bnT3(self.convT3(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.convT4(x)\n",
    "        x = torch.tanh(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.test_generator(Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    \"\"\"\n",
    "    Applies initial weights to certain layers in a model .\n",
    "    The weights are taken from a normal distribution \n",
    "    with mean = 0, std dev = 0.02.\n",
    "    :param m: A module or layer in a network    \n",
    "    \"\"\"\n",
    "    # classname will be something like:\n",
    "    # `Conv`, `BatchNorm2d`, `Linear`, etc.\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    y = 0.02\n",
    "    \n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "def build_network(d_conv_dim, g_conv_dim, z_size):\n",
    "    # define discriminator and generator\n",
    "    D = Discriminator(d_conv_dim)\n",
    "    G = Generator(z_size=z_size, conv_dim=g_conv_dim)\n",
    "\n",
    "    # initialize model weights\n",
    "#     D.apply(weights_init_normal)\n",
    "#     G.apply(weights_init_normal)\n",
    "\n",
    "    print(D)\n",
    "    print()\n",
    "    print(G)\n",
    "    \n",
    "    return D, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_conv_dim = 32\n",
    "g_conv_dim = 32\n",
    "z_size = 100\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "D, G = build_network(d_conv_dim, g_conv_dim, z_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Training on GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discriminator and Generator Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(D_out):\n",
    "    '''Calculates how close discriminator outputs are to being real.\n",
    "       param, D_out: discriminator logits\n",
    "       return: real loss'''\n",
    "    \n",
    "    batch_size = D_out.size(0)\n",
    "    \n",
    "    labels = torch.ones(batch_size)\n",
    "    \n",
    "    # move labels to GPU if available     \n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_loss(D_out):\n",
    "    '''Calculates how close discriminator outputs are to being fake.\n",
    "       param, D_out: discriminator logits\n",
    "       return: fake loss'''\n",
    "    \n",
    "    batch_size = D_out.size(0)\n",
    "    \n",
    "    labels = torch.zeros(batch_size)\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "\n",
    "d_optimizer = optim.Adam(D.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, n_epochs, print_every=50):\n",
    "    '''Trains adversarial networks for some number of epochs\n",
    "       param, D: the discriminator network\n",
    "       param, G: the generator network\n",
    "       param, n_epochs: number of epochs to train for\n",
    "       param, print_every: when to print and record the models' losses\n",
    "       return: D and G losses'''\n",
    "    \n",
    "    # move models to GPU\n",
    "    if train_on_gpu:\n",
    "        D.cuda()\n",
    "        G.cuda()\n",
    "        \n",
    "    # keep track of loss and generated, \"fake\" samples\n",
    "    samples = []\n",
    "    losses = []\n",
    "    \n",
    "    # Get some fixed data for sampling. These are images that are held\n",
    "    # constant throughout training, and allow us to inspect the model's performance\n",
    "    sample_size=16\n",
    "    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "    fixed_z = torch.from_numpy(fixed_z).float()\n",
    "    \n",
    "    # move z to GPU if available\n",
    "    if train_on_gpu:\n",
    "        fixed_z = fixed_z.cuda()\n",
    "        \n",
    "    # epoch training loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # batch training loop\n",
    "        for batch_i, (real_images, _) in enumerate(tqdm(celeba_train_loader)):\n",
    "            \n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            real_images = scale(real_images)\n",
    "            \n",
    "            # ============================================\n",
    "            #            TRAIN THE DISCRIMINATOR\n",
    "            # ============================================\n",
    "            \n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # 1. Train with real images\n",
    "\n",
    "            # Compute the discriminator losses on real images \n",
    "            if train_on_gpu:\n",
    "                real_images = real_images.cuda()\n",
    "                \n",
    "            D_real = D(real_images)\n",
    "            d_real_loss = real_loss(D_real)\n",
    "            \n",
    "            # 2. Train with fake images\n",
    "            fake_images = G(fixed_z)\n",
    "            \n",
    "            # Compute the discriminator losses on fake images            \n",
    "            D_fake = D(fake_images)\n",
    "            d_fake_loss = fake_loss(D_fake)\n",
    "            \n",
    "            # add up loss and perform backprop\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # =========================================\n",
    "            #            TRAIN THE GENERATOR\n",
    "            # =========================================\n",
    "            \n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # 1. Train with fake images and flipped labels\n",
    "            \n",
    "            # Generate fake images\n",
    "            fake_images = G(fixed_z)\n",
    "            \n",
    "            # Compute the discriminator losses on fake images \n",
    "            # using flipped labels!\n",
    "            D_fake = D(fake_images)\n",
    "            g_loss = real_loss(D_fake) # use real loss to flip labels\n",
    "\n",
    "            # perform backprop\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            # Print some loss stats\n",
    "            if batch_i % print_every == 0:\n",
    "                # append discriminator loss and generator loss\n",
    "                losses.append((d_loss.item(), g_loss.item()))\n",
    "                # print discriminator and generator loss\n",
    "                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                        epoch+1, n_epochs, d_loss.item(), g_loss.item()))\n",
    "                \n",
    "        ## AFTER EACH EPOCH##    \n",
    "        # this code assumes your generator is named G, feel free to change the name\n",
    "        # generate and save sample, fake images\n",
    "        G.eval() # for generating samples\n",
    "        samples_z = G(fixed_z)\n",
    "        samples.append(samples_z)\n",
    "        G.train() # back to training mode\n",
    "\n",
    "    # Save training generator samples\n",
    "    with open('train_samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)\n",
    "        \n",
    "    # finally return losses\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(D, G, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
